# qi2lab human olfactory bulb example

## Overview

The goal of this example is to retrieve a 3D MERFISH experiment generated by the qi2lab at ASU from the cloud and run merfish3d-analysis through quantifying transcripts and assigning transcripts to cells. This is a 119-gene MERFISH and 2-gene smFISH experiment on post-mortem human olfactory bulb tissue.

## Preliminaries

You need to make sure you have a working python enviornment with `merfish3d-analysis` properly installed, `Baysor` properly installed, and our human olfactory bulb 3D MERFISH dataset downloaded. The dataset is ~.7 TB and you will need roughly another ~0.5 TB of space to create the `qi2labDataStore` structure we use to perform tile registration, global registration, segmentation, pixel decoding, filtering, and cell assignment.

- [merfish3d-analysis](https://www.github.com/qi2lab/merfish3d-analysis)
= [Raw 3D Human olfactory bulb MERFISH data](https://www.dropbox.com/scl/fo/gwtgsfoa5t65b0wszzamn/ANIjNG6s6RZRHaplw6xCJeQ?rlkey=wzsoq3f0gou4az64yv794r8pi&st=nj1q2fhh&dl=0)
- [Baysor](https://github.com/kharchenkolab/Baysor)

## Downloaded data

In the downloaded data, the directory structure should be as follows:

```bash
/path/to/download/ 
├── raw_data/ 
  ├── data_r0001_tile000_xyz/
  ├── data_r0001_tile000_xyz.csv
  ...
  ...
  ├── data_r0009_tile041_xyz/
  ├── data_r0009_tile041_xyz.csv
  ├── codebook.csv
  ├── bit_order.csv
  ├── hot_pixel_flir.tiff
  └── scan_metadata.csv
```

## Processing steps

All of the required code to process this data is contained within the `merfish3d-analysis` package through command line interfaces (CLI).  The package will automatically utilize multiple GPUs if the `--num-gpu` parameter is passed in with the number of available GPUs. The default value for `--num-gpu` is `1` and the package will use the first GPU that it finds. Because our workstation has two Nvidia 3090 RTXs GPUs, we provide the commands used to process the human olfactory bulb data in the preprint.  

All of the commands given here are run from the terminal.  

Each command list below can be queried using `--help` to discover all of the available parameters, if the defaults are not correct for your dataset. For example,
```bash
conda run --live-stream -n merfished qi2lab-decode --help
```

### Datastore creation including hot pixel correction, camera ADU to photoelectron conversion, illumination estimation, and flatfield correction

```bash
conda run --live-stream -n merfish3d qi2lab-datastore "/path/to/data" --num-gpus 2 --hot-pixel-image "hot_pixel_flir.tiff"
```

### Pre-processing including deconvolution, drift correction, and neural network prediction of spots

```bash
conda run --live-stream -n merfish3d qi2lab-preprocess "/path/to/data" --num-gpus 2
```

### Global registration and first round poly-dT tile fusion

```bash
conda run --live-stream -n merfish3d-stitcher qi2lab-globalregister "/path/to/data"
``` 

### poly-dT cell segmentation

The values for Cellpose-SAM need to be pre-determined using the Cellpose GUI.

```bash
conda run --live-stream -n merfish3d qi2lab-segment "/path/to/data" --diameter 90 --normalization-low 0.5 --normalization-high 99.0 --cellprobthreshold 
```

### Pixel decoding including FDR filtering

Because there are 2 smFISH bits at the end of the codebook, we instruct the `merfish3d-analysis` pixel decoder to process only the initial 16 bits of the codebook.

```bash
conda run --live-stream -n merfish3d qi2lab-decode "/path/to/data" --perform-baysor True --num-gpus 2 --merfish-bits 16
```