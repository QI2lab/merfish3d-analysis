# qi2lab human olfactory bulb example

## Overview

The goal of this example is to retrieve a 3D MERFISH experiment generated by the qi2lab at ASU from the cloud and run merfish3d-analysis through quantifying transcripts and assigning transcripts to cells. This is a 119-gene MERFISH and 2-gene smFISH experiment on post-mortem human olfactory bulb tissue.

## Preliminaries

You need to make sure you have a working python enviornment with `merfish3d-analysis` properly installed, `Baysor` properly installed, and our human olfactory bulb 3D MERFISH dataset downloaded. The dataset is ~700 GB and you will need roughly another ~500 GB of space to create the `qi2labDataStore` structure we use to perform tile registration, global registration, segmentation, pixel decoding, filtering, and cell assignment.

- [merfish3d-analysis](https://www.github.com/qi2lab/merfish3d-analysis)
= [Raw 3D Human olfactory bulb MERFISH data](https://www.dropbox.com/scl/fo/gwtgsfoa5t65b0wszzamn/ANIjNG6s6RZRHaplw6xCJeQ?rlkey=wzsoq3f0gou4az64yv794r8pi&st=nj1q2fhh&dl=0)
- [Baysor](https://github.com/kharchenkolab/Baysor)

## Downloaded data

All of the required code to process this data is cpnt. There should be three top-level directories in the downloaded folder, `raw_data` and `results`. The directory structure is as follows:

```bash
/path/to/download/ 
├── raw_data/ 
  ├── data_r0001_tile000_xyz/
  ├── data_r0001_tile000_xyz.csv
  ...
  ...
  ├── data_r0009_tile041_xyz/
  ├── data_r0009_tile041_xyz.csv
  ├── codebook.csv
  ├── bit_order.csv
  ├── hot_pixel_flir.tiff
  └── scan_metadata.csv
```

## Processing steps

For any dataset generated using qi2lab microscope control code, each step can be executed from the command line. It will automatically utilize multiple GPUs if present and the `--num-gpu` parameter is passed in with the number of available GPUs. Because our workstation has two Nvidia 3090 RTXs GPUs, we provide the commands used to process the data in the preprint here.

First, ensure you have succesfully installed the `merfish3d-analysis` package. The commands given here should be run from your `base` conda (or mamba) environment.

Each command list below can be queried using `--help` to discover all of the available parameters, if the defaults are not correct for your dataset. For example,
```bash
conda run -n merfished qi2lab-decode --help
```

### Datastore creation including hot pixel correction, camera ADU to photoelectron conversion, illumination estimation, and flatfield correction

```bash
conda run -n merfish3d qi2lab-datastore "/path/to/data" --num-gpus 2 --hot-pixel-image "hot_pixel_flir.tiff"
```

### Pre-processing including deconvolution, drift correction, and neural network prediction of spots

```bash
conda run -n merfish3d qi2lab-preprocess "/path/to/data" --num-gpus 2
```

### Global registration and round 1 poly-dT tile fusion

```bash
conda run -n merfish3d-stitcher qi2lab-globalregister "/path/to/data"
``` 

### poly-dT cell segmentation

The values for Cellpose-SAM need to be pre-determined using the Cellpose GUI.

```bash
conda run -n merfish3d qi2lab-segment "/path/to/data" --diameter 90 --normalization-low 0.5 --normalization-high 99.0 --cellprobthreshold 
```

### Pixel decoding including FDR filtering

Because there are 2 smFISH bits at the end of the codebook, we instruct the `merfish3d-analysis` pixel decoder to process only the initial 16 bits of the codebook.

```bash
conda run -n merfish3d qi2lab-decode "/path/to/data" --perform-baysor True --num-gpus 2 --merfish-bits 16
```